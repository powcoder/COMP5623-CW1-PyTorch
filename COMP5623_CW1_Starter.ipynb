{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "COMP5623 CW1 - Starter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdnsT8VYCSYF",
        "colab_type": "text"
      },
      "source": [
        "## COMP5623 Coursework on Image Classification with Convolutional Neural Networks \n",
        "\n",
        "Starter code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKS20wjsCSYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from  torch.utils.data import Dataset\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from skimage import io, transform\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "import math\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpRGGlofCSYM",
        "colab_type": "text"
      },
      "source": [
        "### Part I\n",
        "\n",
        "The first part of the assignment is to build a CNN and train it on a subset of the ImageNet dataset. We will first create a dataframe with all the references to the images and their labels.\n",
        "\n",
        "To download the images into your work environment, clone into a git respository containing the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqhQboSCCSYN",
        "colab_type": "code",
        "outputId": "70075266-a9bf-4459-a46a-4733de6a48d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! git clone https://github.com/MohammedAlghamdi/imagenet10.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'imagenet10'...\n",
            "remote: Enumerating objects: 10019, done.\u001b[K\n",
            "remote: Total 10019 (delta 0), reused 0 (delta 0), pack-reused 10019\u001b[K\n",
            "Receiving objects: 100% (10019/10019), 966.71 MiB | 58.87 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "Checking out files: 100% (10002/10002), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8edZnYShg7M1",
        "colab_type": "text"
      },
      "source": [
        "Check that the repository is there:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2RIZGHaCVAC",
        "colab_type": "code",
        "outputId": "d62a5fc3-1d97-49e4-ca89-76d693fe0d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imagenet10  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47tv-wIQCTcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir = \"imagenet10/train_set/\"\n",
        "class_names = [\n",
        "  \"baboon\",\n",
        "  \"banana\",\n",
        "  \"canoe\",\n",
        "  \"cat\",\n",
        "  \"desk\",\n",
        "  \"drill\",\n",
        "  \"dumbbell\",\n",
        "  \"football\",\n",
        "  \"mug\",\n",
        "  \"orange\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6oMdWl5CSYR",
        "colab_type": "text"
      },
      "source": [
        "A helper function for reading in images and assigning labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQfcD3jyCSYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_meta(root_dir, dirs):\n",
        "    \"\"\" Fetches the meta data for all the images and assigns labels.\n",
        "    \"\"\"\n",
        "    paths, classes = [], []\n",
        "    for i, dir_ in enumerate(dirs):\n",
        "        for entry in os.scandir(root_dir + dir_):\n",
        "            if (entry.is_file()):\n",
        "                paths.append(entry.path)\n",
        "                classes.append(i)\n",
        "                \n",
        "    return paths, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J967KW0CSYX",
        "colab_type": "text"
      },
      "source": [
        "Now we create a dataframe using all the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gDPs1NCCSYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Benign images we will assign class 0, and malignant as 1\n",
        "paths, classes = get_meta(root_dir, class_names)\n",
        "\n",
        "data = {\n",
        "    'path': paths,\n",
        "    'class': classes\n",
        "}\n",
        "\n",
        "data_df = pd.DataFrame(data, columns=['path', 'class'])\n",
        "data_df = data_df.sample(frac=1).reset_index(drop=True) # Shuffles the data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUDj3WihItY",
        "colab_type": "text"
      },
      "source": [
        "View some sample data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK2GPzfVCSYc",
        "colab_type": "code",
        "outputId": "3afe770c-de1a-423c-d38f-fa4bef589b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(\"Found\", len(data_df), \"images.\")\n",
        "data_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9000 images.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>imagenet10/train_set/mug/n03797390_5057.JPEG</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>imagenet10/train_set/canoe/n02951358_4726.JPEG</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>imagenet10/train_set/orange/n07747607_1509.JPEG</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>imagenet10/train_set/cat/n02123159_5997.JPEG</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>imagenet10/train_set/dumbbell/n03255030_8507.JPEG</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path  class\n",
              "0       imagenet10/train_set/mug/n03797390_5057.JPEG      8\n",
              "1     imagenet10/train_set/canoe/n02951358_4726.JPEG      2\n",
              "2    imagenet10/train_set/orange/n07747607_1509.JPEG      9\n",
              "3       imagenet10/train_set/cat/n02123159_5997.JPEG      3\n",
              "4  imagenet10/train_set/dumbbell/n03255030_8507.JPEG      6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai3uvziWCSYh",
        "colab_type": "text"
      },
      "source": [
        "Now we will create the Dataset class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyUb-rzQCSYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageNet10(Dataset):\n",
        "    \"\"\" ImageNet10 dataset. \"\"\"\n",
        "\n",
        "    def __init__(self, df, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_dir (string): Directory with all the images\n",
        "            df (DataFrame object): Dataframe containing the images, paths and classes\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load image from path and get label\n",
        "        x = Image.open(self.df['path'][index])\n",
        "        try:\n",
        "          x = x.convert('RGB') # To deal with some grayscale images in the data\n",
        "        except:\n",
        "          pass\n",
        "        y = torch.tensor(int(self.df['class'][index]))\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqtRjBozCSYk",
        "colab_type": "text"
      },
      "source": [
        "Compute what we should normalise the dataset to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPqfMPuZCSYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_img_mean_std(image_paths):\n",
        "    \"\"\"\n",
        "        Author: @xinruizhuang. Computing the mean and std of three channel on the whole dataset,\n",
        "        first we should normalize the image from 0-255 to 0-1\n",
        "    \"\"\"\n",
        "\n",
        "    img_h, img_w = 224, 224\n",
        "    imgs = []\n",
        "    means, stdevs = [], []\n",
        "\n",
        "    for i in tqdm(range(len(image_paths))):\n",
        "        img = cv2.imread(image_paths[i])\n",
        "        img = cv2.resize(img, (img_h, img_w))\n",
        "        imgs.append(img)\n",
        "\n",
        "    imgs = np.stack(imgs, axis=3)\n",
        "    print(imgs.shape)\n",
        "\n",
        "    imgs = imgs.astype(np.float32) / 255.\n",
        "\n",
        "    for i in range(3):\n",
        "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
        "        means.append(np.mean(pixels))\n",
        "        stdevs.append(np.std(pixels))\n",
        "\n",
        "    means.reverse()  # BGR --> RGB\n",
        "    stdevs.reverse()\n",
        "\n",
        "    print(\"normMean = {}\".format(means))\n",
        "    print(\"normStd = {}\".format(stdevs))\n",
        "    return means, stdevs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_1KSGUe4sEW",
        "colab_type": "code",
        "outputId": "10224973-d6c2-411e-edad-ddcdf8a327ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "norm_mean, norm_std = compute_img_mean_std(paths)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 3367/9000 [00:16<00:25, 221.95it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqrG3FCUCSYo",
        "colab_type": "text"
      },
      "source": [
        "Now let's create the transforms to normalise and turn our data into tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVeZpgM-CSYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(norm_mean, norm_std),\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAPzCfr2CSYt",
        "colab_type": "text"
      },
      "source": [
        "Let's split the data into train and test sets and instantiate our new ISIC_Dataset objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POCexxXjCSYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_split = 0.70 # Defines the ratio of train/valid/test data.\n",
        "valid_split = 0.10\n",
        "\n",
        "train_size = int(len(data_df)*train_split)\n",
        "valid_size = int(len(data_df)*valid_split)\n",
        "\n",
        "ins_dataset_train = ImageNet10(\n",
        "    df=data_df[:train_size],\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "ins_dataset_valid = ImageNet10(\n",
        "    df=data_df[train_size:(train_size + valid_size)].reset_index(drop=True),\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "ins_dataset_test = ImageNet10(\n",
        "    df=data_df[(train_size + valid_size):].reset_index(drop=True),\n",
        "    transform=data_transform,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzVfNzvmhTGJ",
        "colab_type": "text"
      },
      "source": [
        "You will need to create DataLoaders for the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_womtSmIhgSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X00vuzPWhY5h",
        "colab_type": "text"
      },
      "source": [
        "A framework for the ConvNet model, missing all layers except the final fully-connected layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B5x07o3CSY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional neural network\n",
        "class ConvNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "  \n",
        "        # Add network layers here\n",
        "\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.final = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        # Complete the graph\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}